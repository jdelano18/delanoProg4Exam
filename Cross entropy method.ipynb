{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start epoch 0\n",
      "deviation mean = 10.0\n",
      "test end with reward: [-1499.18663864]\n",
      "start epoch 1\n",
      "deviation mean = 11.348508533430941\n",
      "test end with reward: [-1656.53788569]\n",
      "start epoch 2\n",
      "deviation mean = 10.5154989854672\n",
      "test end with reward: [-895.16819746]\n",
      "start epoch 3\n",
      "deviation mean = 11.458376403298658\n",
      "test end with reward: [-138.65170979]\n",
      "start epoch 4\n",
      "deviation mean = 10.360312620184294\n",
      "test end with reward: [-1501.06955974]\n",
      "start epoch 5\n",
      "deviation mean = 11.473431544328815\n",
      "test end with reward: [-137.84779373]\n",
      "start epoch 6\n",
      "deviation mean = 10.053089447499207\n",
      "test end with reward: [-132.48289306]\n",
      "start epoch 7\n",
      "deviation mean = 8.817873390205383\n",
      "test end with reward: [-1505.34641595]\n",
      "start epoch 8\n",
      "deviation mean = 8.652870869354295\n",
      "test end with reward: [-954.53800206]\n",
      "start epoch 9\n",
      "deviation mean = 7.913195826309426\n",
      "test end with reward: [-248.93505109]\n",
      "start epoch 10\n",
      "deviation mean = 7.570025969332937\n",
      "test end with reward: [-362.66624103]\n",
      "start epoch 11\n",
      "deviation mean = 6.663809939754934\n",
      "test end with reward: [-134.84783509]\n",
      "start epoch 12\n",
      "deviation mean = 6.2935322105297775\n",
      "test end with reward: [-1.75152617]\n",
      "start epoch 13\n",
      "deviation mean = 6.187517151799455\n",
      "test end with reward: [-120.90899836]\n",
      "start epoch 14\n",
      "deviation mean = 6.809303742474397\n",
      "test end with reward: [-335.81728848]\n",
      "start epoch 15\n",
      "deviation mean = 6.13037704158553\n",
      "test end with reward: [-355.19497577]\n",
      "start epoch 16\n",
      "deviation mean = 6.605138003187941\n",
      "test end with reward: [-1321.82174851]\n",
      "start epoch 17\n",
      "deviation mean = 6.163700096040749\n",
      "test end with reward: [-2.91454154]\n",
      "start epoch 18\n",
      "deviation mean = 5.997821410265183\n",
      "test end with reward: [-471.74388688]\n",
      "start epoch 19\n",
      "deviation mean = 5.417523898058404\n",
      "test end with reward: [-606.49051174]\n",
      "start epoch 20\n",
      "deviation mean = 4.890559373541396\n",
      "test end with reward: [-423.65668131]\n",
      "start epoch 21\n",
      "deviation mean = 4.930902763230067\n",
      "test end with reward: [-466.92720618]\n",
      "start epoch 22\n",
      "deviation mean = 5.38261123897279\n",
      "test end with reward: [-121.70561515]\n",
      "start epoch 23\n",
      "deviation mean = 4.566199447782195\n",
      "test end with reward: [-129.15599333]\n",
      "start epoch 24\n",
      "deviation mean = 4.742581136774498\n",
      "test end with reward: [-370.09689659]\n",
      "start epoch 25\n",
      "deviation mean = 4.541832410340904\n",
      "test end with reward: [-357.86515109]\n",
      "start epoch 26\n",
      "deviation mean = 4.42765487350343\n",
      "test end with reward: [-245.31922425]\n",
      "start epoch 27\n",
      "deviation mean = 4.359099988450836\n",
      "test end with reward: [-127.8129609]\n",
      "start epoch 28\n",
      "deviation mean = 4.24040247147821\n",
      "test end with reward: [-218.62027349]\n",
      "start epoch 29\n",
      "deviation mean = 3.6818278549017447\n",
      "test end with reward: [-2.5766805]\n",
      "start epoch 30\n",
      "deviation mean = 3.4523969009311815\n",
      "test end with reward: [-124.38206054]\n",
      "start epoch 31\n",
      "deviation mean = 3.0556798579060263\n",
      "test end with reward: [-130.13521462]\n",
      "start epoch 32\n",
      "deviation mean = 3.252887801204113\n",
      "test end with reward: [-361.30602231]\n",
      "start epoch 33\n",
      "deviation mean = 3.1960341985952603\n",
      "test end with reward: [-2.77997083]\n",
      "start epoch 34\n",
      "deviation mean = 3.412848670941135\n",
      "test end with reward: [-366.8885241]\n",
      "start epoch 35\n",
      "deviation mean = 3.024730383095633\n",
      "test end with reward: [-2.18634466]\n",
      "start epoch 36\n",
      "deviation mean = 3.039569777545483\n",
      "test end with reward: [-130.85549503]\n",
      "start epoch 37\n",
      "deviation mean = 3.0245117403120383\n",
      "test end with reward: [-134.49963836]\n",
      "start epoch 38\n",
      "deviation mean = 3.133591456292536\n",
      "test end with reward: [-230.41792865]\n",
      "start epoch 39\n",
      "deviation mean = 3.0266096633331556\n",
      "test end with reward: [-366.6931976]\n",
      "start epoch 40\n",
      "deviation mean = 2.2029996428003296\n",
      "test end with reward: [-121.55189499]\n",
      "start epoch 41\n",
      "deviation mean = 2.2891001551924424\n",
      "test end with reward: [-245.15579356]\n",
      "start epoch 42\n",
      "deviation mean = 2.1450374486724053\n",
      "test end with reward: [-248.80059119]\n",
      "start epoch 43\n",
      "deviation mean = 2.009850116130276\n",
      "test end with reward: [-122.71513765]\n",
      "start epoch 44\n",
      "deviation mean = 1.8014212902618463\n",
      "test end with reward: [-369.86560337]\n",
      "start epoch 45\n",
      "deviation mean = 1.750707886011959\n",
      "test end with reward: [-363.30626946]\n",
      "start epoch 46\n",
      "deviation mean = 1.9024180482495383\n",
      "test end with reward: [-125.37703099]\n",
      "start epoch 47\n",
      "deviation mean = 1.601838131361429\n",
      "test end with reward: [-1490.97942452]\n",
      "start epoch 48\n",
      "deviation mean = 1.4832284971060847\n",
      "test end with reward: [-121.46641016]\n",
      "start epoch 49\n",
      "deviation mean = 1.3577818233623142\n",
      "test end with reward: [-129.56975893]\n",
      "start epoch 50\n",
      "deviation mean = 1.1191396200112638\n",
      "test end with reward: [-124.03478694]\n",
      "start epoch 51\n",
      "deviation mean = 1.0272764027340264\n",
      "test end with reward: [-248.54687486]\n",
      "start epoch 52\n",
      "deviation mean = 1.0989580336507039\n",
      "test end with reward: [-124.04475358]\n",
      "start epoch 53\n",
      "deviation mean = 1.1176383761336053\n",
      "test end with reward: [-409.74303324]\n",
      "start epoch 54\n",
      "deviation mean = 1.227829546755731\n",
      "test end with reward: [-117.50789982]\n",
      "start epoch 55\n",
      "deviation mean = 1.4269334423173172\n",
      "test end with reward: [-125.69320596]\n",
      "start epoch 56\n",
      "deviation mean = 1.5160323981394088\n",
      "test end with reward: [-431.33644378]\n",
      "start epoch 57\n",
      "deviation mean = 1.492900367563378\n",
      "test end with reward: [-1.51850578]\n",
      "start epoch 58\n",
      "deviation mean = 1.5006351911125886\n",
      "test end with reward: [-131.68917654]\n",
      "start epoch 59\n",
      "deviation mean = 1.4327411680982534\n",
      "test end with reward: [-223.68079111]\n",
      "start epoch 60\n",
      "deviation mean = 1.4012458962160006\n",
      "test end with reward: [-123.12610668]\n",
      "start epoch 61\n",
      "deviation mean = 1.1958241571968864\n",
      "test end with reward: [-237.51059883]\n",
      "start epoch 62\n",
      "deviation mean = 1.0888104769765359\n",
      "test end with reward: [-403.64284553]\n",
      "start epoch 63\n",
      "deviation mean = 1.0043042839081526\n",
      "test end with reward: [-126.26556352]\n",
      "start epoch 64\n",
      "deviation mean = 1.1009431898863524\n",
      "test end with reward: [-123.33972942]\n",
      "start epoch 65\n",
      "deviation mean = 1.0917586505935455\n",
      "test end with reward: [-118.36887204]\n",
      "start epoch 66\n",
      "deviation mean = 0.9571125016966187\n",
      "test end with reward: [-243.89495506]\n",
      "start epoch 67\n",
      "deviation mean = 0.96683306846534\n",
      "test end with reward: [-129.99017872]\n",
      "start epoch 68\n",
      "deviation mean = 1.1236462726980752\n",
      "test end with reward: [-3.65158586]\n",
      "start epoch 69\n",
      "deviation mean = 0.8501654436230544\n",
      "test end with reward: [-125.37705612]\n",
      "start epoch 70\n",
      "deviation mean = 0.7562257077768285\n",
      "test end with reward: [-121.53002925]\n",
      "start epoch 71\n",
      "deviation mean = 0.7050280303332405\n",
      "test end with reward: [-132.33714235]\n",
      "start epoch 72\n",
      "deviation mean = 0.6230782893582413\n",
      "test end with reward: [-444.24407934]\n",
      "start epoch 73\n",
      "deviation mean = 0.3595735402354475\n",
      "test end with reward: [-131.10007073]\n",
      "start epoch 74\n",
      "deviation mean = 0.3501339595769282\n",
      "test end with reward: [-242.8474051]\n",
      "start epoch 75\n",
      "deviation mean = 0.2961396217444477\n",
      "test end with reward: [-124.12000495]\n",
      "start epoch 76\n",
      "deviation mean = 0.306101503341137\n",
      "test end with reward: [-134.60065764]\n",
      "start epoch 77\n",
      "deviation mean = 0.3350726207570977\n",
      "test end with reward: [-2.88998947]\n",
      "start epoch 78\n",
      "deviation mean = 0.26235877267720614\n",
      "test end with reward: [-126.78093358]\n",
      "start epoch 79\n",
      "deviation mean = 0.28980813399332644\n",
      "test end with reward: [-2.2926811]\n",
      "--- 7143.305414915085 seconds ---\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "author: Thyrix Yang\n",
    "github: https://github.com/ThyrixYang\n",
    "'''\n",
    "import time\n",
    "start_time = time.time()\n",
    "\n",
    "import numpy as np \n",
    "import gym\n",
    "scores = []\n",
    "\n",
    "class CEMOptimizer:\n",
    "\n",
    "  def __init__(self, weights_dim, batch_size=1000, deviation=10, deviation_lim=100, rho=0.1, eta=0.1, mean=None):\n",
    "    self.rho = rho\n",
    "    self.eta = eta\n",
    "    self.weights_dim = weights_dim\n",
    "    self.mean = mean if mean!=None else np.zeros(weights_dim)\n",
    "    self.deviation = np.full(weights_dim, deviation)\n",
    "    self.batch_size = batch_size\n",
    "    self.select_num = int(batch_size * rho)\n",
    "    self.deviation_lim = deviation_lim\n",
    "\n",
    "    assert(self.select_num > 0)\n",
    "\n",
    "  def update_weights(self, weights, rewards):\n",
    "    rewards = np.array(rewards).flatten()\n",
    "    weights = np.array(weights)\n",
    "    sorted_idx = (-rewards).argsort()[:self.select_num]\n",
    "    top_weights = weights[sorted_idx]\n",
    "    top_weights = np.reshape(top_weights, (self.select_num, self.weights_dim))\n",
    "    self.mean = np.sum(top_weights, axis=0) / self.select_num\n",
    "    self.deviation = np.std(top_weights, axis=0)\n",
    "    self.deviation[self.deviation > self.deviation_lim] = self.deviation_lim\n",
    "    if(len(self.deviation)!=self.weights_dim):\n",
    "      print(\"dim error\")\n",
    "      print(len(self.deviation))\n",
    "      print(self.weights_dim)\n",
    "      exit()\n",
    "\n",
    "    #method to create random weights \n",
    "  def sample_batch_weights(self):\n",
    "    return [np.random.normal(self.mean, self.deviation * (1 + self.eta)) \\\n",
    "        for _ in range(self.batch_size)]\n",
    "\n",
    "  def get_weights(self):\n",
    "    return self.mean\n",
    "\n",
    "\n",
    "\n",
    "def train():\n",
    "\n",
    "  def select_action(ob, weights):\n",
    "    b1 = np.reshape(weights[0], (1, 1))\n",
    "    w1 = np.reshape(weights[1:4], (1, 3))\n",
    "    b2 = np.reshape(weights[4:7], (3, 1))\n",
    "    w2 = np.reshape(weights[7:16], (3, 3))\n",
    "    w3 = np.reshape(weights[16:25], (3, 3))\n",
    "    b3 = np.reshape(weights[25:], (3, 1))\n",
    "    ob = np.reshape(ob, (3, 1))\n",
    "    action = np.dot(w1, np.tanh(np.dot(w2, np.tanh(np.dot(w3, ob) - b3)) - b2)) - b1\n",
    "    return np.tanh(action) * 2\n",
    "\n",
    "  #set up environment\n",
    "  opt = CEMOptimizer(3*3+3*3+3*1+3*1+3*1+1, 500, rho=0.01, eta=0.3, deviation=10, deviation_lim=20)\n",
    "  env = gym.make(\"Pendulum-v0\")\n",
    "  env = gym.wrappers.Monitor(env, '/tmp/cartpole-experiment-3', force=True)\n",
    "  epoch = 80\n",
    "  run_times = 10\n",
    "\n",
    "  def test():\n",
    "    W = opt.get_weights()\n",
    "    observation = env.reset()\n",
    "    accreward = 0\n",
    "    while True:\n",
    "      env.render()\n",
    "      action = select_action(observation, W)\n",
    "      observation, reward, done, info = env.step(action)\n",
    "      accreward += reward\n",
    "      if done:\n",
    "        print(\"test end with reward: {}\".format(accreward))\n",
    "        scores.append(accreward)\n",
    "        #print(scores)\n",
    "        break\n",
    "\n",
    "  for ep in range(epoch):\n",
    "    print(\"start epoch {}\".format(ep))\n",
    "    weights = opt.sample_batch_weights() #randomize weights\n",
    "    rewards = []\n",
    "    opt.eta *= 0.99\n",
    "    print(\"deviation mean = {}\".format(np.mean(opt.deviation)))\n",
    "    for b in range(opt.batch_size):\n",
    "      accreward = 0\n",
    "      for _ in range(run_times):  \n",
    "        observation = env.reset()  \n",
    "        while True: #action updated continuously\n",
    "          action = select_action(observation, weights[b])\n",
    "          observation, reward, done, info = env.step(action)\n",
    "          accreward += reward\n",
    "          if done:\n",
    "            break\n",
    "      rewards.append(accreward)\n",
    "    opt.update_weights(weights, rewards)\n",
    "    test()\n",
    "\n",
    "if __name__ == '__main__':\n",
    "  train()\n",
    "  print(\"--- %s seconds ---\" % (time.time() - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaned = [float(i) for i in scores]\n",
    "index = [i for i in range(0,len(cleaned))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Index       Reward\n",
      "0       0 -1499.186639\n",
      "1       1 -1656.537886\n",
      "2       2  -895.168197\n",
      "3       3  -138.651710\n",
      "4       4 -1501.069560\n",
      "5       5  -137.847794\n",
      "6       6  -132.482893\n",
      "7       7 -1505.346416\n",
      "8       8  -954.538002\n",
      "9       9  -248.935051\n",
      "10     10  -362.666241\n",
      "11     11  -134.847835\n",
      "12     12    -1.751526\n",
      "13     13  -120.908998\n",
      "14     14  -335.817288\n",
      "15     15  -355.194976\n",
      "16     16 -1321.821749\n",
      "17     17    -2.914542\n",
      "18     18  -471.743887\n",
      "19     19  -606.490512\n",
      "20     20  -423.656681\n",
      "21     21  -466.927206\n",
      "22     22  -121.705615\n",
      "23     23  -129.155993\n",
      "24     24  -370.096897\n",
      "25     25  -357.865151\n",
      "26     26  -245.319224\n",
      "27     27  -127.812961\n",
      "28     28  -218.620273\n",
      "29     29    -2.576680\n",
      "..    ...          ...\n",
      "50     50  -124.034787\n",
      "51     51  -248.546875\n",
      "52     52  -124.044754\n",
      "53     53  -409.743033\n",
      "54     54  -117.507900\n",
      "55     55  -125.693206\n",
      "56     56  -431.336444\n",
      "57     57    -1.518506\n",
      "58     58  -131.689177\n",
      "59     59  -223.680791\n",
      "60     60  -123.126107\n",
      "61     61  -237.510599\n",
      "62     62  -403.642846\n",
      "63     63  -126.265564\n",
      "64     64  -123.339729\n",
      "65     65  -118.368872\n",
      "66     66  -243.894955\n",
      "67     67  -129.990179\n",
      "68     68    -3.651586\n",
      "69     69  -125.377056\n",
      "70     70  -121.530029\n",
      "71     71  -132.337142\n",
      "72     72  -444.244079\n",
      "73     73  -131.100071\n",
      "74     74  -242.847405\n",
      "75     75  -124.120005\n",
      "76     76  -134.600658\n",
      "77     77    -2.889989\n",
      "78     78  -126.780934\n",
      "79     79    -2.292681\n",
      "\n",
      "[80 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "dataframe = pd.DataFrame({\n",
    "    'Index': index,\n",
    "    'Reward':cleaned\n",
    "})\n",
    "\n",
    "print(dataframe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bokeh.io import output_file, output_notebook, show\n",
    "from bokeh.plotting import figure\n",
    "\n",
    "# create the plot\n",
    "p = figure(plot_width=900, plot_height=600,\n",
    "          x_axis_label='Epoch Number',\n",
    "           y_axis_label='Reward at End of Test',\n",
    "          title='Performance of Cross-Entropy Method')\n",
    "\n",
    "# add multiple line glyph\n",
    "p.line(x=dataframe['Index'], y=dataframe['Reward'], \n",
    "       color='black', legend='Reward', line_width=5)\n",
    "\n",
    "# use this next line to instead output the plot in the jupyter notebook\n",
    "#output_notebook()\n",
    "output_file(\"Cross_Entropy_Method\")\n",
    "\n",
    "# show the plot\n",
    "show(p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
